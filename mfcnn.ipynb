{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "# Convolution using mxnet  ### x w\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import itertools, time\n",
    "import torch\n",
    "print('PyTorch version:', torch.__version__)\n",
    "\n",
    "import scipy\n",
    "from scipy.signal import convolve, fftconvolve, tukey, deconvolve\n",
    "\n",
    "\n",
    "\n",
    "def get_im2col_indices(x_shape, field_height, field_width, padding=1, stride=1):\n",
    "    # First figure out what the size of the output should be\n",
    "    N, C, H, W = x_shape\n",
    "    assert (H + 2 * padding - field_height) % stride == 0\n",
    "    assert (W + 2 * padding - field_height) % stride == 0\n",
    "    out_height = (H + 2 * padding - field_height) // stride + 1\n",
    "    out_width = (W + 2 * padding - field_width) // stride + 1\n",
    "\n",
    "    i0 = np.repeat(np.arange(field_height), field_width)\n",
    "    i0 = np.tile(i0, C)\n",
    "    i1 = stride * np.repeat(np.arange(out_height), out_width)\n",
    "    j0 = np.tile(np.arange(field_width), field_height * C)\n",
    "    j1 = stride * np.tile(np.arange(out_width), out_height)\n",
    "    i = i0.reshape(-1, 1) + i1.reshape(1, -1)\n",
    "    j = j0.reshape(-1, 1) + j1.reshape(1, -1)\n",
    "\n",
    "    k = np.repeat(np.arange(C), field_height * field_width).reshape(-1, 1)\n",
    "\n",
    "    return (k, i, j)\n",
    "\n",
    "\n",
    "def im2col_indices(x, field_height, field_width, padding=1, stride=1):\n",
    "    \"\"\" An implementation of im2col based on some fancy indexing \"\"\"\n",
    "    # Zero-pad the input\n",
    "    p = padding\n",
    "    x_padded = np.pad(x, ((0, 0), (0, 0), (p, p), (p, p)), mode='constant')\n",
    "\n",
    "    k, i, j = get_im2col_indices(x.shape, field_height, field_width, padding,\n",
    "                               stride)\n",
    "\n",
    "    cols = x_padded[:, k, i, j]\n",
    "    C = x.shape[1]\n",
    "    cols = cols.transpose(1, 2, 0).reshape(field_height * field_width * C, -1)\n",
    "    return cols\n",
    "\n",
    "\n",
    "def col2im_indices(cols, x_shape, field_height=3, field_width=3, padding=1,\n",
    "                   stride=1):\n",
    "    \"\"\" An implementation of col2im based on fancy indexing and np.add.at \"\"\"\n",
    "    N, C, H, W = x_shape\n",
    "    H_padded, W_padded = H + 2 * padding, W + 2 * padding\n",
    "    x_padded = np.zeros((N, C, H_padded, W_padded), dtype=cols.dtype)\n",
    "    k, i, j = get_im2col_indices(x_shape, field_height, field_width, padding,\n",
    "                               stride)\n",
    "    cols_reshaped = cols.reshape(C * field_height * field_width, -1, N)\n",
    "    cols_reshaped = cols_reshaped.transpose(2, 0, 1)\n",
    "    np.add.at(x_padded, (slice(None), k, i, j), cols_reshaped)\n",
    "    if padding == 0:\n",
    "        return x_padded\n",
    "    return x_padded[:, :, padding:-padding, padding:-padding]\n",
    "\n",
    "def conv_forward_naive(x, w, b, conv_param):\n",
    "    \"\"\"\n",
    "    A naive implementation of the forward pass for a convolutional layer.\n",
    "    The input consists of N data points, each with C channels, height H and width\n",
    "    W. We convolve each input with F different filters, where each filter spans\n",
    "    all C channels and has height HH and width HH.\n",
    "    Input:\n",
    "    - x: Input data of shape (N, C, H, W)\n",
    "    - w: Filter weights of shape (F, C, HH, WW)\n",
    "    - b: Biases, of shape (F,)\n",
    "    - conv_param: A dictionary with the following keys:\n",
    "    - 'stride': The number of pixels between adjacent receptive fields in the\n",
    "      horizontal and vertical directions.\n",
    "    - 'pad': The number of pixels that will be used to zero-pad the input.\n",
    "    Returns a tuple of:\n",
    "    - out: Output data, of shape (N, F, H', W') where H' and W' are given by\n",
    "    H' = 1 + (H + 2 * pad - HH) / stride\n",
    "    W' = 1 + (W + 2 * pad - WW) / stride\n",
    "    - cache: (x, w, b, conv_param)\n",
    "    \"\"\"\n",
    "    out = None\n",
    "    N, C, H, W = x.shape\n",
    "    F, C, HH, WW = w.shape\n",
    "    pad, stride = conv_param['pad'], conv_param['stride']\n",
    "    x_stretched = im2col_indices(x, HH, WW, padding=pad, stride=stride)\n",
    "    w_stretched = im2col_indices(w, HH, WW, padding=0, stride=1)\n",
    "    H_prime = 1 + (H + 2*pad - HH) // stride\n",
    "    W_prime = 1 + (W + 2*pad - WW) // stride\n",
    "    out_shape = (N, F, H_prime, W_prime)\n",
    "    out = col2im_indices(w_stretched.T.dot(x_stretched) + b[:,np.newaxis], \n",
    "                       out_shape, field_height=1, field_width=1, padding=0, \n",
    "                       stride=1)\n",
    "    cache = (x, w, b, conv_param)\n",
    "    return out, cache\n",
    "\n",
    "class Benchmark(): \n",
    "    def __init__(self, prefix=None):\n",
    "        self.prefix = prefix + ' ' if prefix else ''\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        print('%stime: %.4f sec' % (self.prefix, time.time() - self.start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积定理\n",
    "\n",
    "Ref: [Proofs of Parseval’s Theorem & the Convolution Theorem](http://wwwf.imperial.ac.uk/~jdg/eeft3.pdf)\n",
    "\n",
    "若 $f_1(t) \\leftrightarrow F_1(\\omega), f_2(t)\\leftrightarrow F_2(\\omega)$，则有\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "F[f_1(t)\\star f_2(t)]&=F_1(\\omega)\\cdot F_2(\\omega)\\\\\n",
    "F[f_1(t)\\cdot f_2(t)]&=F_1(\\omega)\\star F_2(\\omega)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- 卷积定理\n",
    "\n",
    "    - ANN out (scratch): \n",
    "    \n",
    "        `x(t) * w(t)`\n",
    "        \n",
    "    - np.fft (scratch): \n",
    "    \n",
    "        `abs( ifft[ fft[x(t), mod=2xsize(x)-1] · fft[w(-t), mod=2xsize(x)-1] ] )`\n",
    "        \n",
    "    - scipy.fft (scratch):\n",
    "        \n",
    "        `abs( ifft[ fft[x(t), mod=2xsize(x)-1] · fft[w(-t), mod=2xsize(x)-1] ] )`\n",
    "\n",
    "    - np.convolve:\n",
    "    \n",
    "        `x(t) * w(-t)`\n",
    "        \n",
    "    - scipy.signal.convolve/fftconvolve:\n",
    "    \n",
    "        `x(t) * w(-t)`\n",
    "        \n",
    "    - mxnet.ndarray.Convolution:\n",
    "    \n",
    "        `x(t) * w(t)`\n",
    "    - torch.nn.Conv1d/torch.nn.Conv2d:\n",
    "\n",
    "        `x(t) * w(t)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "卷积定理\n",
      "==========\n",
      "x: [[[[0 1 2 3 4 5 6 7 8 9]]]]\n",
      "w: [[[[0 1 2 3 4 5 6 7 8 9]]]] b: [0] \n",
      "\n",
      "ANN out (scratch): (1, 1, 19, 19) \n",
      " [  0   9  26  50  80 115 154 196 240 285 240 196 154 115  80  50  26   9\n",
      "   0]\n",
      "np.fft (scratch):\n",
      " [  0   8  25  49  79 114 153 196 240 285 240 196 154 114  79  50  26   8\n",
      "   0]\n",
      "scipy.fft (scratch):\n",
      " [  0   8  25  49  80 114 153 196 240 285 240 196 154 114  79  50  26   8\n",
      "   0]\n",
      "np.convolve:\n",
      " [  0   9  26  50  80 115 154 196 240 285 240 196 154 115  80  50  26   9\n",
      "   0]\n",
      "scipy.signal.convolve:\n",
      " [  0   9  26  50  80 115 154 196 240 285 240 196 154 115  80  50  26   9\n",
      "   0]\n",
      "scipy.signal.fftconvolve:\n",
      " [  0   9  25  50  80 115 154 196 240 285 240 196 154 114  80  50  26   9\n",
      "   0]\n",
      "pytorch out (1d): torch.Size([1, 1, 19]) \n",
      " [  0   9  26  50  80 115 154 196 240 285 240 196 154 115  80  50  26   9\n",
      "   0]\n",
      "pytorch out (2d): torch.Size([1, 1, 1, 19]) \n",
      " [  0   9  26  50  80 115 154 196 240 285 240 196 154 115  80  50  26   9\n",
      "   0]\n"
     ]
    }
   ],
   "source": [
    "print('='*10+'\\n卷积定理\\n'+'='*10)\n",
    "\n",
    "x = np.arange(10).reshape(1,1,1,10)\n",
    "w = np.arange(10).reshape(1,1,1,10)\n",
    "b = np.arange(1)\n",
    "print('x:',x)\n",
    "print('w:',w,'b:',b, '\\n')\n",
    "\n",
    "# Convolution using ANN by scratch ### x w\n",
    "conv_param = {'pad': w.shape[-1]-1,\n",
    "              'stride': 1}\n",
    "out, cache = conv_forward_naive(x, w, b, conv_param) # (1, 1, 19, 19)\n",
    "print('ANN out (scratch):',out.shape,'\\n', out[0,0,w.shape[-1]-1])\n",
    "\n",
    "# Convolution by scratch ### x w[::-1]\n",
    "print('np.fft (scratch):\\n',np.abs(np.fft.ifft( np.fft.fft(x[0,0,0],w.shape[-1]*2-1) * np.fft.fft(w[0,0,0][::-1],w.shape[-1]*2-1) )).astype(np.int32))\n",
    "print('scipy.fft (scratch):\\n',np.abs(scipy.fft.ifft( scipy.fft.fft(x[0,0,0],w.shape[-1]*2-1) * scipy.fft.fft(w[0,0,0][::-1],w.shape[-1]*2-1) )).astype(np.int32))\n",
    "\n",
    "# Convolution using numpy  ### x w[::-1]\n",
    "print('np.convolve:\\n', np.convolve(x[0,0,0], w[0,0,0][::-1]))\n",
    "\n",
    "# Convolution using scipy  ### x w[::-1]\n",
    "print('scipy.signal.convolve:\\n', convolve(x[0,0,0], w[0,0,0][::-1]))\n",
    "print('scipy.signal.fftconvolve:\\n', fftconvolve(x[0,0,0], w[0,0,0][::-1]).astype(np.int32))\n",
    "\n",
    "# Mxnet\n",
    "out = nd.Convolution(data=nd.array(x), weight=nd.array(w), bias=nd.array(b), kernel=w.shape[-2:],\n",
    "                                  num_filter=w.shape[1], pad=(0,w.shape[-1]-1))  # \n",
    "print('mxnet out:', out.shape, '\\n', out[0,0,0].asnumpy().astype(np.int32))\n",
    "\n",
    "# FFT & iFFT etc. for torch vs numpy\n",
    "assert np.allclose( torch.fft.fftfreq(4096).numpy() , np.fft.fftfreq(4096) )\n",
    "assert np.allclose( torch.fft.fft(torch.tensor(w)[0,0,0]).numpy() , np.fft.fft(w[0,0,0]) )\n",
    "assert np.allclose( torch.fft.ifft(torch.tensor(w)[0,0,0]).numpy() , np.fft.ifft(w[0,0,0]) )\n",
    "assert np.allclose( torch.fft.rfft(torch.tensor(w)[0,0,0]).numpy() , np.fft.rfft(w[0,0,0]) )\n",
    "assert np.allclose( torch.fft.irfft(torch.tensor(w)[0,0,0]).numpy() , np.fft.irfft(w[0,0,0]) , atol=1e-7)\n",
    "assert np.allclose( np.fft.fft2(np.mgrid[:5, :5][0]) , torch.fft.fft2(torch.tensor(np.mgrid[:5, :5][0])) , atol=1e-6)\n",
    "assert np.allclose( np.fft.ifft2(np.mgrid[:5, :5][0]) , torch.fft.ifft2(torch.tensor(np.mgrid[:5, :5][0])) )\n",
    "\n",
    "conv = torch.nn.Conv1d(1,1,kernel_size=w.shape[-1], padding=w.shape[-1]-1)\n",
    "conv.weight=torch.nn.Parameter(torch.from_numpy(w[0]).float(), requires_grad=False)\n",
    "conv.bias=torch.nn.Parameter(torch.from_numpy(b).float(), requires_grad=False)\n",
    "\n",
    "out = conv(torch.from_numpy(x[0]).float())\n",
    "print('pytorch out (1d):', out.shape, '\\n', out[0,0].int().numpy())\n",
    "\n",
    "conv = torch.nn.Conv2d(1,1,kernel_size=w.shape[-2:], padding=(0,w.shape[-1]-1))\n",
    "conv.weight=torch.nn.Parameter(torch.from_numpy(w).float(), requires_grad=False)\n",
    "conv.bias=torch.nn.Parameter(torch.from_numpy(b).float(), requires_grad=False)\n",
    "\n",
    "out = conv(torch.from_numpy(x).float())\n",
    "print('pytorch out (2d):', out.shape, '\\n', out[0,0,0].int().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">以上是卷积定理在不同的计算逻辑下，实现的相同结果。\n",
    ">\n",
    ">同时，还考察了 `torch` 的 `fft` 模块也 `numpy` 的数值精度对应性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积 vs 相关\n",
    "\n",
    "> Ref: \n",
    "> 1. [二维kernel信息上的关系](https://www.mathworks.com/help/images/what-is-image-filtering-in-the-spatial-domain.html)\n",
    "> 2. [Wiki: 各种定义和性质](https://en.wikipedia.org/wiki/Cross-correlation)\n",
    "> 3. [知名的 Note](http://www.cs.umd.edu/~djacobs/CMSC426/Convolution.pdf)\n",
    "> 4. [关联的证明](https://math.stackexchange.com/questions/1090974/relation-between-correlation-and-convolution)\n",
    "\n",
    "- 卷积 + 相关：\n",
    "\n",
    "  $$\n",
    "  \\begin{align}\n",
    "  f(t) * g(t) &= \\int^{+\\infty}_{-\\infty}f(\\tau)\\cdot g(t-\\tau)d\\tau = \\int^{+\\infty}_{-\\infty}f(t-\\tau)\\cdot g(\\tau)d\\tau \\\\\n",
    "  f(t) \\star g(t) &= \\int^{+\\infty}_{-\\infty}f^*(\\tau)\\cdot g(t+\\tau)d\\tau = \\int^{+\\infty}_{-\\infty}f^*(\\tau-t)\\cdot g(\\tau)d\\tau\n",
    "  \\end{align}\n",
    "  $$\n",
    "  \n",
    "  定义关联：\n",
    "  $$\n",
    "  \\begin{align}\n",
    "  f(t)\\star g(t)=f^*(-t) * g(t)\n",
    "  \\end{align}\n",
    "  $$\n",
    "  卷积定理关联：\n",
    "  $$\n",
    "  \\begin{align}\n",
    "  F\\{f*g\\}&=F\\{f\\}\\cdot F\\{g\\}\\\\\n",
    "  F\\{f\\star g\\}&=(F\\{f\\})^*\\cdot F\\{g\\}\\\\\n",
    "  \\end{align}\n",
    "  $$\n",
    "\n",
    "\n",
    "\n",
    "- 卷积 vs 相关\n",
    "\n",
    "    - np.fft (scratch) (LIGO):\n",
    "    \n",
    "    `abs( ifft[ fft[x(t), mod=10] · fft[w(t), mod=10].conjugate() ] )`\n",
    "    \n",
    "    - np.correlate + mod-10:\n",
    "    \n",
    "    `Mod[ x(t)`$\\star$`w(t) , 10](-t)`\n",
    "    \n",
    "    - np.convolue + mod-10:\n",
    "    \n",
    "    `Mod[ x(t) * w(-t) , 10](-t)`\n",
    "    \n",
    "    - mxnet.ndarray.Convolution + mod-10:\n",
    "    \n",
    "    `Mod[ x(t) * w(t) , 10](-t)`\n",
    "\n",
    "    - torch.nn.Con1d/torch.nn.Con2d + mod-10:\n",
    "    \n",
    "    `Mod[ x(t) * w(t) , 10](t)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod(out, mod):\n",
    "#     if type(out) == type(nd.array(1)):\n",
    "#         return nd.concatenate([out, nd.zeros(out.shape[:-1]+(mod - out.shape[-1]%mod, ), ctx=ctx)], axis=len(out.shape)-1).reshape(0,0,-1,mod).sum(axis=-2).expand_dims(2)[:,:,:,::-1]\n",
    "    if type(out) == type(torch.tensor(1)):\n",
    "        return torch.cat((out, torch.zeros(out.shape[:-1]+(mod - out.shape[-1]%mod,))), dim=len(out.shape)-1).reshape(-1,mod).sum(axis=-2)\n",
    "    elif type(out) == type(np.array(1)):\n",
    "        return np.concatenate([out, np.zeros(out.shape[:-1]+(mod - out.shape[-1]%mod, ) )], axis=len(out.shape)-1).reshape(-1,mod).sum(axis=-2)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "卷积 vs 相关\n",
      "==========\n",
      "np.fft (scratch):\n",
      " [285 240 205 180 165 160 165 180 205 240]\n",
      "np.fft (scratch | full):\n",
      " [285 240 196 154 115  79  49  25   8   8  25  49  79 115 154 196 240]\n",
      "np.correlate:\n",
      " [  0   9  26  50  80 115 154 196 240 285 240 196 154 115  80  50  26   9\n",
      "   0]\n",
      "np.correlate (mod=10):\n",
      " [285 240 205 180 165 160 165 180 205 240]\n",
      "np.convolve:\n",
      " [  0   9  26  50  80 115 154 196 240 285 240 196 154 115  80  50  26   9\n",
      "   0]\n",
      "np.convolve (mod=10):\n",
      " [285 240 205 180 165 160 165 180 205 240]\n",
      "pytorch out (1d): torch.Size([1, 1, 21]) \n",
      " [285 240 205 180 165 160 165 180 205 240]\n",
      "pytorch out (1d) with mod func: torch.Size([1, 1, 21]) \n",
      " [285 240 205 180 165 160 165 180 205 240]\n",
      "pytorch out (2d): torch.Size([1, 1, 1, 21]) \n",
      " [285 240 205 180 165 160 165 180 205 240]\n",
      "pytorch out (2d) with mod func: torch.Size([1, 1, 1, 21]) \n",
      " [285 240 205 180 165 160 165 180 205 240]\n"
     ]
    }
   ],
   "source": [
    "print('='*10+'\\n卷积 vs 相关\\n'+'='*10) ### x w\n",
    "\n",
    "print('np.fft (scratch):\\n',np.abs(np.fft.ifft( np.fft.fft(x[0,0,0]) * np.fft.fft(w[0,0,0]).conjugate() )).astype(np.int32) )\n",
    "print('np.fft (scratch | full):\\n',np.abs(np.fft.ifft( np.fft.fft(x[0,0,0], 9*2-1) * np.fft.fft(w[0,0,0], 9*2-1).conjugate() )).astype(np.int32) )\n",
    "print('np.correlate:\\n', np.correlate(x[0,0,0], w[0,0,0], mode='full') )\n",
    "print('np.correlate (mod=10):\\n', mod(np.correlate(x[0,0,0], w[0,0,0], mode='full') , mod=10).astype(np.int32) )\n",
    "print('np.convolve:\\n', np.convolve(x[0,0,0], w[0,0,0][::-1], mode='full'))\n",
    "print('np.convolve (mod=10):\\n', mod( np.convolve(x[0,0,0], w[0,0,0][::-1], mode='full'), mod=10).astype(np.int32) )\n",
    "\n",
    "# Mxnet\n",
    "# out = nd.Convolution(data=nd.array(x), weight=nd.array(w), bias=nd.array(b), kernel=w.shape[-2:],stride=(1,1),\n",
    "#                                   num_filter=w.shape[1], pad=(0,w.size-1))  # \n",
    "# print('mxnet out:',out.shape,'\\n',out[0,0,0].asnumpy().astype(np.int32))\n",
    "# print('mxnet out (mod=10):',out.shape,'\\n',mod( out, mod=10)[0,0,0].asnumpy().astype(np.int32) )\n",
    "\n",
    "# out = nd.Convolution(data=nd.array(x), weight=nd.array(w), bias=nd.array(b), kernel=w.shape[-2:],stride=(1,1),\n",
    "#                                   num_filter=w.shape[1], pad=(0,w.size))  # \n",
    "# print('mxnet out:',out.shape,'\\n',out[0,0,0,:-1].reshape(2,-1).sum(axis=0).asnumpy().astype(np.int32))\n",
    "\n",
    "conv = torch.nn.Conv1d(1,1,kernel_size=w.shape[-1], padding=w.shape[-1])\n",
    "conv.weight=torch.nn.Parameter(torch.from_numpy(w[0]).float(), requires_grad=False)\n",
    "conv.bias=torch.nn.Parameter(torch.from_numpy(b).float(), requires_grad=False)\n",
    "\n",
    "out = conv(torch.from_numpy(x[0]).float())\n",
    "print('pytorch out (1d):', out.shape, '\\n', out[:,:,:-1].reshape(2,-1).sum(axis=0).int().numpy())\n",
    "\n",
    "print('pytorch out (1d) with mod func:', out.shape, '\\n', mod(out, mod=10).int().numpy())\n",
    "\n",
    "conv = torch.nn.Conv2d(1,1,kernel_size=w.shape[-2:], padding=(0, w.shape[-1]),)\n",
    "conv.weight=torch.nn.Parameter(torch.from_numpy(w).float(), requires_grad=False)\n",
    "conv.bias=torch.nn.Parameter(torch.from_numpy(b).float(), requires_grad=False)\n",
    "\n",
    "out = conv(torch.from_numpy(x).float())\n",
    "print('pytorch out (2d):', out.shape, '\\n', out[:,:,:,:-1].reshape(2,-1).sum(axis=0).int().numpy())\n",
    "\n",
    "print('pytorch out (2d) with mod func:', out.shape, '\\n', mod(out, mod=10).int().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模 vs 自相关 (omited)\n",
    "\n",
    "- 模 vs 自相关 (omited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('模 vs 自相关\\n'+'='*10) ### x w\n",
    "\n",
    "# print('np.correlate:\\n', abs(np.fft.fft(np.correlate(x[0,0,0], x[0,0,0], mode='full'))) )\n",
    "# (abs(np.fft.fft(x[0,0,0], 9*2-1)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 内积(分母) vs 自相关\n",
    "\n",
    "- 内积(分母) vs 自相关\n",
    "\n",
    "    - $<x|x>$\n",
    "    \n",
    "    `sum[ fft[ x(t), mod=10] · fft[ x(t), mod=10 ].conjugate() ] x df`\n",
    "    \n",
    "    - np.correlate + mod-10:\n",
    "    \n",
    "    `Mod[ x(t)`$\\star$`w(t) , 10](0) x fs`\n",
    "    \n",
    "    - mxnet.ndarray.Convolution + mod-10:\n",
    "    \n",
    "    `Mod[ x(t) * w(t) , 10](0) x fs`\n",
    "    \n",
    "    - torch.nn.Conv1d/torch.nn.Conv2d + mod-10:\n",
    "    \n",
    "    `Mod[ x(t) * w(t) , 10](0) x fs`    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内积(分母) vs 自相关  df: 255.9\n",
      "====================\n",
      "分母: \n",
      " (729315+0j)\n",
      "np.correlate (mod=10):\n",
      " 729315.0\n",
      "pytorch out (1d) (mod=10): torch.Size([1, 1, 21]) \n",
      " 729315\n",
      "pytorch out (2d) (mod=10): torch.Size([1, 1, 1, 21]) \n",
      " 729315\n"
     ]
    }
   ],
   "source": [
    "fs = np.random.randint(1, 4096)\n",
    "datafreq = np.fft.fftfreq(x[0,0,0].size)*fs\n",
    "df = np.abs(datafreq[1] - datafreq[0])\n",
    "print('内积(分母) vs 自相关'+'  df: %s\\n'% df +'='*20) ### x w\n",
    "\n",
    "print('分母: \\n', ( np.fft.fft(x[0,0,0]) * np.fft.fft(x[0,0,0]).conjugate() ).sum()* df)\n",
    "\n",
    "print('np.correlate (mod=10):\\n', mod( np.correlate(x[0,0,0], x[0,0,0], mode='full') ,mod=10)[0] * fs)\n",
    "\n",
    "# out = nd.Convolution(data=nd.array(x), weight=nd.array(x), bias=nd.array(b), kernel=w.shape[-2:],stride=(1,1),\n",
    "#                                   num_filter=w.shape[1], pad=(0,w.size-1))  # \n",
    "# print('mxnet out (mod=10):',out.shape,'\\n',mod( out, mod=10)[0,0,0,0].asnumpy().astype(np.int32) * fs)\n",
    "\n",
    "conv = torch.nn.Conv1d(1,1,kernel_size=x.shape[-1], padding=x.shape[-1])\n",
    "conv.weight=torch.nn.Parameter(torch.from_numpy(x[0]).float(), requires_grad=False)\n",
    "conv.bias=torch.nn.Parameter(torch.from_numpy(b).float(), requires_grad=False)\n",
    "\n",
    "out = conv(torch.from_numpy(x[0]).float())\n",
    "print('pytorch out (1d) (mod=10):',out.shape,'\\n',mod( out, mod=10)[0].int().numpy() * fs)\n",
    "\n",
    "conv = torch.nn.Conv2d(1,1,kernel_size=x.shape[-2:], padding=(0,x.shape[-1]))\n",
    "conv.weight=torch.nn.Parameter(torch.from_numpy(x).float(), requires_grad=False)\n",
    "conv.bias=torch.nn.Parameter(torch.from_numpy(b).float(), requires_grad=False)\n",
    "\n",
    "out = conv(torch.from_numpy(x).float())\n",
    "print('pytorch out (2d) (mod=10):',out.shape,'\\n',mod( out, mod=10)[0].int().numpy() * fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCNN with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.0.dev20190402', True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__, torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[device(type='cuda', index=0),\n",
       " device(type='cuda', index=1),\n",
       " device(type='cuda', index=2),\n",
       " device(type='cuda', index=3)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_all_gpus():\n",
    "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\"\"\"\n",
    "    devices = [torch.device(f'cuda:{i}')\n",
    "             for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]     \n",
    "devices = try_all_gpus()\n",
    "devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('train_data_z3_random_AE_with_gb_16384.npy') # (6000, 2, 16384) [17384 * 15]sec\n",
    "train_label = np.zeros((6000,)) \n",
    "train_label[3000:] = 1\n",
    "\n",
    "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "# train_label = torch.tensor(pd.get_dummies(train_label).values, dtype=torch.float32)\n",
    "train_label = torch.tensor(train_label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "dataset = TensorDataset(train_data, train_label)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, \n",
    "                          shuffle=True, #pin_memory=True,\n",
    "#                           num_workers=16,\n",
    "                          worker_init_fn=lambda _: np.random.seed(\n",
    "                              int(torch.initial_seed()) % (2**32-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 16384])\n",
      "torch.Size([50, 2, 4096])\n"
     ]
    }
   ],
   "source": [
    "S_t_m12 = np.load('S_t.npy')[::-1]\n",
    "S_t_m12 = torch.tensor(abs(S_t_m12), dtype=torch.float32).reshape(1, 1, 16384)\n",
    "# S_t_m12 = torch.cat((S_t_m12, S_t_m12), 1)  # [2, 1, 16384]\n",
    "print(S_t_m12.shape)\n",
    "\n",
    "template = np.load('template_St_matrix_z3_AE_4096_50.npy')\n",
    "template = torch.tensor(template, dtype=torch.float32).reshape(-1, 2, 4096) #(50, 2, 4096) [4096 x 15]sec\n",
    "print(template.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh_sqrt = np.load('hh_sqrt_4096_50.npy') # (50, 2) \n",
    "hh_sqrt = torch.tensor(hh_sqrt, dtype=torch.float32)\n",
    "hh_sqrt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): MFLayer(\n",
      "    (params): ParameterDict(\n",
      "        (S_t_m12): Parameter containing: [torch.FloatTensor of size 1x1x16384]\n",
      "        (hh_sqrt): Parameter containing: [torch.FloatTensor of size 1x50x2x1]\n",
      "        (template): Parameter containing: [torch.FloatTensor of size 50x2x4096]\n",
      "    )\n",
      "  )\n",
      "  (1): CutHybridLayer()\n",
      "  (2): Conv1d(2, 16, kernel_size=(3,), stride=(1,))\n",
      "  (3): ReLU()\n",
      "  (4): MaxPool1d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv1d(16, 32, kernel_size=(3,), stride=(1,))\n",
      "  (6): ReLU()\n",
      "  (7): MaxPool1d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Flatten()\n",
      "  (9): Linear(in_features=288, out_features=32, bias=True)\n",
      "  (10): ReLU()\n",
      "  (11): Dropout(p=0.5)\n",
      "  (12): Linear(in_features=32, out_features=2, bias=True)\n",
      "  (13): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MFLayer(nn.Module):\n",
    "    def __init__(self,template, hh_sqrt, S_t_m12):\n",
    "        super(MFLayer, self).__init__() \n",
    "        self.data_size = S_t_m12.shape[-1] # 16384\n",
    "        self.temp_size = template.shape[-1] # 4096\n",
    "        self.params = nn.ParameterDict({\n",
    "                'template': nn.Parameter(template, requires_grad=False),\n",
    "                'hh_sqrt': nn.Parameter(hh_sqrt.unsqueeze(0).unsqueeze(-1), requires_grad=False), \n",
    "                'S_t_m12': nn.Parameter(S_t_m12, requires_grad=False),\n",
    "        })\n",
    "\n",
    "    def _mod(self, X, mod):\n",
    "        return F.pad(X, pad=(0, (-X.shape[-1]) % mod)).unsqueeze(-2).reshape(X.shape[0],-1, abs((-X.shape[-1]) // mod), mod).sum(-2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # split A & E\n",
    "        xa = X[:,:1]\n",
    "        xe = X[:,1:]\n",
    "        \n",
    "        # d / sqrt(S)\n",
    "        d_SA = self._mod(F.conv1d(xa, self.params['S_t_m12'], padding=self.data_size-1, groups=1), mod=self.data_size)\n",
    "        d_SE = self._mod(F.conv1d(xe, self.params['S_t_m12'], padding=self.data_size-1, groups=1), mod=self.data_size)\n",
    "        # [num_batch, 1, self.data_size]\n",
    "        \n",
    "        h_SA = self.params['template'][:,:1]\n",
    "        h_SE = self.params['template'][:,1:]\n",
    "        # [num_temp, 1, self.temp_size]\n",
    "        \n",
    "        # <d|h>   \n",
    "        dh_A = self._mod(F.conv1d(d_SA, h_SA, padding=self.temp_size-1, groups=1), mod=self.data_size)\n",
    "        dh_E = self._mod(F.conv1d(d_SE, h_SE, padding=self.temp_size-1, groups=1), mod=self.data_size)\n",
    "        \n",
    "        # [num_batch, num_temp, 2, self.data_size]\n",
    "        return torch.stack((dh_A, dh_E), -2) / self.params['hh_sqrt']\n",
    "\n",
    "class CutHybridLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, X):\n",
    "        return torch.max(torch.abs(X), -1).values.permute(0,2,1)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, X):\n",
    "        return torch.flatten(X, start_dim=1)\n",
    "\n",
    "net = nn.Sequential(\n",
    "    MFLayer(template, hh_sqrt, S_t_m12), \n",
    "    CutHybridLayer(),\n",
    "    nn.Conv1d(in_channels=2, out_channels=16, kernel_size=3, stride=1),\n",
    "    nn.ReLU(), \n",
    "    nn.MaxPool1d(kernel_size=4, stride=2),\n",
    "    nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1),\n",
    "    nn.ReLU(), \n",
    "    nn.MaxPool1d(kernel_size=4, stride=2),\n",
    "#     nn.Flatten(),\n",
    "    Flatten(),\n",
    "    nn.Linear(288, 32),\n",
    "    nn.ReLU(), \n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(32, 2),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = net(train_data[:10])\n",
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = nn.DataParallel(net, device_ids=devices)#.to(devices[0])\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, wd = 1e-3, 1e-4\n",
    "lr_period, lr_decay = 2, 0.9\n",
    "num_epochs = 20\n",
    "\n",
    "trainer = torch.optim.Adam((param for param in net.parameters() if param.requires_grad), \n",
    "                           lr=lr, weight_decay=wd)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_period, lr_decay)\n",
    "num_batches = len(train_loader)\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5386, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1e5a868109d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#     if valid_iter is not None:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_default_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0msuffixes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dtype='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mnonzero_finite_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        features, labels = features.cuda(), labels.cuda()\n",
    "        trainer.zero_grad()\n",
    "        output = net(features)\n",
    "        l = loss(output, labels).mean()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "        print(l)\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
